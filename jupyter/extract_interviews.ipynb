{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962dd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom, então, estou aqui com o Joca, sou Samuel, você já me conhece, e eu estou querendo validar uma aplicação que a gente está fazendo para o projeto de NLP, que é basicamente o quê? Conhece o Reddit? A rede social? Sei, o Reddit. Sei que é um blog, um fórum. É um blog, tipo, muita gente, é muito ativo, né? De tudo. Gigantesco. Fórum sobre tudo. Exato. E é um grande fundo de dados, assim, dependendo do que você quer fazer. E daí a minha ideia, qual que é a ideia da nossa aplicação? A gente extrair comentários e blogs dentro da plataforma do Reddit, tá ligado? Só que comentários e blogs que vão ter algum teor, certo? Que revelam alguma dor do usuário. Alguma dor, tipo, algum problema que eles estão sentindo. Atitude de oportunidade. É, atitude de oportunidade, porque se eu pego esses comentários, esses blogs, certo? Eu consigo classificar eles, dizendo, tipo, se eles têm algum teor ou não, que revela algum problema do usuário. E depois que eu classifico, eu consigo meio que agrupar eles em dores similares. Tá bom. A ideia é que eu tente agrupar eles em dores similares. Entender quais são as maiores dores. Exato. As maiores dores de cada grupamento. E eu pergunto, no Reddit tem fórum sobre tudo. Você vai agrupar essas dores por todos os fóruns ou por alguns fóruns? Pronto, eu predefini alguns fóruns. Eles geralmente são fóruns de empreendedorismos mesmo. E fóruns, tipo, mas eu pesquisei, né? A gente fez uma pesquisa de fóruns que poderiam dar esse tipo de... Insight. Esse tipo de insight, tipo, que poderia ter mensagens lá que a gente poderia conseguir de alguma forma extrair, tipo... Oportunidades. Oportunidades. E daí tem empreendedorismo, tem social media, tem um que é... Não existe dúvida besta, então qualquer dúvida vai existir por lá. E aí por diante. Então é isso. Mundo afora ou só Brasil? É... Mundo afora, mundo afora. E daí, essa é a ideia. E daí eu queria saber, tipo, o que é que tu acha, tipo, se pra tu faz sentido? Como que isso impactaria? Você, tipo, na tua visão de empreendedor hoje, se é uma coisa legal. Eu acho que faz muito sentido, porque na medida que, quanto maior essa amostra, de fato, se você vê que tem mil pessoas falando que uma dor ali, aquela dor pode ser, realmente pode ser um problema. É mais eficiente do que você sair por aí perguntando. É, exato. Então você consegue, a título de amostra, fazer uma amostragem muito maior. Portanto, achar um problema muito mais importante. E a remuneração de qualquer empreendedor costuma ser, usualmente, quão grave é o problema que ele resolve. Perfeito. Quão especializado ele precisa ser pra resolver um dado problema. E também, qual a quantidade de pessoas. Você quer um mix entre um problema grave, que afeta muitas pessoas. Aí você estourou. Perfeito. Porque, pô, se você resolve um problema, se você achou um problema, que já tem uma companhia muito grande resolvendo esse problema, eu acho isso do caralho, tá? Sempre alguém perguntar, mas não tem ninguém fazendo isso. Ótimo que tem alguém já fazendo isso. Já tá validado. Já tá validado. Ou, sei lá, eu não acho que você precisa arremeter a roda pra ganhar dinheiro. Perfeito. E, inclusive, eu vejo muita gente falando exatamente isso de olhar no Reddit, porque eu sigo muita gente que faz microsass. E o pessoal tá fazendo microsass com várias AIs, com Excel. E o pessoal sempre fala de justamente não só ver a dor pelo Reddit, tanto quanto, uma vez feita a solução, também divulgar no Reddit. Também divulgar no Reddit, perfeito. Eu acho que o Reddit é um canal de originação e distribuição de soluções muito legal. Perfeito. Muito legal. Eu gosto muito. Você vai realmente fazer isso? Eu tô fazendo já. Nossa, deve estar dando um trabalho do caralho, hein? É, dando um trabalhinho. Tipo, eu já tenho uma... Preview? É, um preview. Ah, é? Porque eu tô falando português aqui. E daí, só pra finalizar, tu acha que na tua percepção gera valor isso aí? Gera muito valor. Você pode gerar um... Eu, sendo você, logo em seguida faria um report super bem estruturado, postaria no LinkedIn, tipo, essas são as maiores dores que as pessoas têm hoje em dia. Tipo, alguma coisa assim. Legal. E tentaria, talvez, se você conseguisse avaliar não só a dor, a magnitude da dor, quanto a predisposição da pessoa pagar pra resolver aquela dor, talvez fosse bacana. Como você vai fazer isso, eu não sei. Não, fechou. Talvez se você tivesse, tipo, se você, não sei, se você tiver alguma forma de quantificar o quão predispostas as pessoas são pra resolver um determinado dor, eu acho que isso é bacana também. Que aí é o PEC. Uma dor grande pra muita gente, que as pessoas querem pagar pra resolver, puta, iniciando. Iniciando. Mas eu adorei. Eu realmente ficaria muito curioso, tá? Se eu tivesse em processo de discovery pra achar uma tese de uma companhia ou de um projeto, eu com certeza adoraria esse jeito de screen, digamos assim. Boa, boa. Muito legal. Vou te mostrar então depois. Então é isso. Obrigadão. E você tem que gravar tudo isso pra matéria? É, porque ele quer...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "audio_file= open(\"../data/audio/WhatsApp Audio 2025-06-03 at 22.59.34.mp4\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ac5ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom, boa noite. Estou aqui com o Hudson, sou o Samuel Jabes. E bom, Hudson, hoje estou aqui para falar um pouco da aplicação que a gente está construindo na nossa matéria, né? Redutiva de NLP. E basicamente, do que é que se trata a aplicação? Você conhece o Reddit? Sim, conheço. Você sabe que o Reddit tem uma grande quantidade de dados, né? Tipo, é uma plataforma muito ativa, né? Sobre qualquer coisa, os usuários podem ir lá comentar, postar alguma coisa, é uma rede social. E sempre tem muito dado lá que a gente pode extrair para fazer alguma coisa com algum intuito. E daí, o nosso intuito é justamente extrair esses dados. Esses dados são comentários ou postagens de usuários na plataforma e verificar se esses comentários ou posts, eles têm algum teor que revela algum teor de problema, que vai revelar ali alguma problemática em relação ao usuário, alguma dor que o usuário sente. E dado que a gente filtra esses comentários que revelam a dor de um usuário, a nossa ideia é agrupar todos esses comentários que revelam dores em clusters, de dores similares. E dado que a gente agrupa em clusters diferentes, de dores similares, a gente, para cada cluster, a gente vai passar ali por um IA que vai meio que extrair os principais tópicos, as principais dores que existem dentro desses clusters. E daí, a ideia é justamente a gente passar esse relatório que a gente extrai para empreendedores, o nosso usuário ideal, mais especificamente empreendedores que estão ali, estão vendo o processo de discovery e querem encontrar oportunidades de montar o seu próprio negócio. E aí a questão é, dado essa aplicação que a gente faz, eu queria ver se do teu ponto de vista ela faz sentido, se ela gera valor na tua visão como empreendedor, acho que não só para você, mas para o geral, é válido? Enfim. Eu acho que para mim não faz muito sentido essa aplicação, porque eu não sei qual é a resposta que você vai colocar desse IA para fazer esses clusters, o que você está usando para fazer esses clusters? É só basicamente chat de IPT, alguma coisa específica? A gente utiliza um algoritmo de clusterização, que é o K-Means, que ele vai basicamente tomar, meio que vizinhos próximos, ali matematicamente, ele vai converter esses dados em valores numéricos e essas representações numéricas desses comentários, a gente consegue ter algum tipo de métrica de similaridade e o algoritmo ele já vai agrupar meio que nesse sentido, baseado na representação numérica desses valores. E a parte de gerar o relatório, a gente utiliza um LLM, da OpenAI mesmo, um GPT-4, e é isso. Interessante, mas eu gosto do ser humano ainda coletando esses dados, avaliando texto por texto e tagueando isso manualmente para poder obter uma apuração melhor da análise de sentimento feito por pessoa que reclamou no post específico do Reddit, como você falou. Acho que tem valor, mas provavelmente ainda vai ter uma interação humana ali para validar de alguma forma essa primeira etapa, para dizer que a intenção da pessoa que comentou, ela queria falar sobre uma dor específica tal, essa parte de classificação aí que vocês estão pensando em fazer, porque acredito que seja bem complexo. Sim, então você acha que nesse processo, ao invés de ser um IA que classifique, você acredita que a intervenção humana seria mais eficaz? Acredito que sim, porque a gente... Eu não sei como é que vai ser feita essa parte de extrair a informação do post para classificar em alguma coisa, sabe? Tipo assim, esse aqui está falando sobre uma dor relacionada à saúde, algo nesse sentido. Então, como é que vai ser feito esse processo? Não entendi muito bem ainda a aplicação de vocês. Você pode repetir, por favor? Como é que vai ser feita essa etapa aí de classificação das mensagens? Você pega um post e você vai classificar isso como... Isso. Depois passar para um ano. Então, o intuito era também utilizar um IA. A gente vai tomar esses dados por meio de scripts, por meio de código, e dado que a gente puxa o comentário ou post, a gente utilizar um IA baseado ali, seguindo uma certa regra, que já é passado para ela, para ela classificar se a mensagem que eu passo para ela no prompt, se ela vai ter algum teor de problema ali do usuário ou não. E aí eu deixo à mercê do próprio modelo decidir, ter esse poder de decisão. E aí eu só filtro porque os comentários em que ele identifica que há, de fato, uma dor do usuário revelada na mensagem. Então você vai usar o LLM para primeiro classificar, depois vai usar o LLM para criar o relatório. Sim. Não tem um modelo baseline que você poderia utilizar para essa etapa? Tipo, já resolveria o seu problema de classificação, talvez? Atualmente não, mas é possível criar. Nós teríamos que apenas scrapar, no caso, extrair mais dados e rotular eles manualmente. Então teria, durante esse processo aí, tem essa etapa então de rotular os dados. Pode levar um tempinho a mais. Mas dado que a gente consiga rotular e consiga um bom número de dados no nosso banco ali que a gente ia construir, a gente consegue treinar um classificador que seria o baseline. E daí, dado um novo comentário que a gente extraísse futuramente, um novo dia, a gente utilizava esse classificador. Entendi. E aí poderia ter, no caso, o nosso viés humano, né? Teria, de fato, o nosso viés humano porque é a gente que está rotulando os dados. Então, quando ele ia treinar em cima disso, ele vai estar enviesado. Eu, como empreendedor, eu teria cautela de usar essa ferramenta e entender esse relatório porque eu gosto de entender de onde os dados vieram e como eles foram feitos para chegar naquela conclusão final. Então, para mim faz sentido a ferramenta no geral, mas eu acho que tem gargalos aí que eu ficaria com o pé atrás de utilizar o relatório como base para atacar um nicho específico e empreender em uma área específica. Deixa eu aproveitar e perguntar a questão de tempo, né? Porque dado que a gente... Eu entendo que você acha que é bom ter mais intervenção humana do que a gente deixar tudo à mercê da IA. É, de fato, uma pontuação bem importante. Mas em relação ao tempo, a gente sabe que se a gente deixa tudo à mercê da IA, às vezes pode sair mais rápido do que quando a gente tem o toque humano. Mas você acha que mesmo vale mais a gente garantir o toque humano em desprezo do tempo? Ou você acha que o tempo ainda é bom a se considerar? Talvez estudar outras alternativas de agilizar? Eu gosto da ideia de agilizar, mas ainda acho que a precisão tem que levar mais em consideração. Prefiro que seja mais assertivo e eu garanto e prove que ele está sendo assertivo do que arriscar e falar, beleza, a IA faz tudo, ela sabe o que está fazendo e vai me entregar um output que eu vou confiar 100% de acurácia. Então eu preciso... A precisão e a acurácia são mais sentidas para mim. Então eu prefiro que demore o processo e eu consiga falar, pô, faz sentido o processo todinho aqui para chegar nessa informação, nesse relatório final. Eu posso confiar e atacar esse nicho que ele tem uma dor específica real aqui acontecendo. Entendi. Então, show. Agradeço aí pelos pontos trazidos e é isso. Obrigado pela conversa. Nada.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "audio_file= open(\"../data/audio/Insper-Instituto-de-Ensino-e-Pesquisa-12.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876e9b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom, boa tarde. Hoje eu estou aqui com o Moreto, sou o Samuel Jarvis. Bom, Moreto, o que eu estou querendo te apresentar aqui hoje é um projeto, uma aplicação que a gente está fazendo na matéria de NLP, que é basicamente voltada para o nicho de empreendedores, às vezes mais especificamente para empreendedores que estão no processo de discovery, encontrar algum tipo de oportunidade. E como é que funciona mais ou menos a aplicação que a gente está fazendo? Você conhece o Reddit? Reddit é a rede social, posts todos os dias. Lá tem uma quantidade massiva de dados e o intuito é a gente extrair alguns comentários e posts dentro de alguns fóruns lá do Reddit. E desses comentários que a gente extrai, a gente classificar, ou a gente filtrar no caso, por comentários que revelam de alguma forma alguma dor que o usuário sente ou está sentindo no momento que ele comenta, ou seja, algum problema que ele relata. E dado que a gente faz filtro, a gente pega as únicas mensagens que revelam uma dor e tenta agrupar ela por dores. A gente pega todos os grupos de mensagens e agrupa elas em dores semelhantes. E uma vez que a gente agrupa ela em dores semelhantes, com algum algoritmo de IA, a gente extrai, usa também um LLM para extrair principais dores, principais tópicos que existem dentro desses clusters. E aí o intuito é, com esses principais tópicos a gente fornecer meio que um relatório, fornecer para o nosso usuário, que o nosso usuário ideal no caso seria o empreendedor, as principais dores que a gente extrai dos comentários do pessoal do Reddit e ajuda o empreendedor a enxergar algum tipo de oportunidade e tentar criar alguma solução em cima. Então basicamente essa é a nossa aplicação. E a minha ideia aqui é só tentar entender um pouco do teu ponto de vista, se para tu isso faz sentido, se gera valor de alguma forma e se você tem algum comentário ou ponto a comentar, enfim. É isso. Eu acho que tem valor sim, eu mesmo já fiz pesquisa no Reddit, mas sem ferramenta é difícil você chegar a uma conclusão, porque você não consegue padronizar, cada comentário é algum tipo, é difícil nichar, então eu acho que tem bastante valor sim, principalmente quando você está olhando de forma mais global, acho que é bastante utilizado lá fora, soluções globais acho que tem bastante valor. Tem só um ponto que talvez eu adicionaria que talvez seria legal, é a questão de um possível direcionamento, tipo algum nicho, se desse para essa ferramenta dar uma nichada, tipo no setor financeiro, e se fizer uma coisa um pouco mais interativa, eu acho que teria bastante valor. Os fóruns que a gente pesquisa são fóruns especificamente de empreendedorismo, de economia inclusive, de saúde e de perguntas em gerais, para ver, tem comentários gerais assim, para não enver azar tanto para nichos mais específicos, mas em geral é isso. Mas se, digamos, sair alguma coisa lá e eu quiser dar uma pesquisa mais direcionada a algum nicho que eu imaginei que pode ser, ele faz? Ele pode tentar selecionar um fórum, pode sim, a gente só precisa setar esse tipo de opção, mas é basicamente isso. Ele só hoje, do modo que está, demora um pouquinho, mas se há algo ali que poderia rodar durante a semana, automaticamente, acho que não vai ter tanto esse peso e você teria ali um relatório semanal. E daí acho que é isso. Você conhece alguma solução que já faz algo parecido? Não conheço. Mas fechou então. Algo a mais? Obrigado.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "audio_file= open(\"../data/audio/Insper-Instituto-de-Ensino-e-Pesquisa-11.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be57e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opa, boa tarde. Sou Samuel Jabes, estou aqui com o Henrico Casol, que é empreendedor. E Henrico, eu estou aqui querendo conversar contigo porque estou desenvolvendo uma aplicação, que é um projeto da matéria de NLP e eu estou precisando validar essa aplicação. Basicamente a minha aplicação é voltada para o nicho de empreendedores, mais especificamente empreendedores que estão no processo de discovery. A aplicação é um pouco mais voltada para isso. E ela basicamente se trata de... Você conhece o Reddit? Reddit. Reddit, exato. Reddit, certo? Reddit tem uma quantidade massiva de dados lá, posts todos os dias, comentários, seja qual for o assunto, certo? E você pode concordar comigo que lá a gente pode ter muito dado, a gente pode adquirir muito dado interessante, dependendo do objetivo que a gente tem. E aí a ideia é o quê? Eu pegar comentários e posts lá no Reddit, que de alguma forma ele tem algum teor de problema do usuário nesse comentário. Ou seja, o usuário revela alguma dor que ele sente, algum problema que ele tem passado, certo? E a minha ideia é justamente extrair esses comentários, classificar se justamente esses comentários ou posts tem esse teor com viés problemático do ponto de vista do usuário, isso com AI. E dos que são classificados como teor problemático, que tem ali uma dor para o usuário, eu gostaria de fazer meio que uma clasterização, agrupar esses comentários para ver, basicamente agrupar em dores, certo? E do que eu agrupo em dores, eu poderia passar por uma camada de um modelo de linguagem para ele me extrair as principais dores dentro de cada cluster. E a aplicação é basicamente essa, a ideia é que os empreendedores possam ter uma noção do que é que hoje em dia é bem atual, porque o Reddit é totalmente ativo, dia a dia, e eles possam ter noção de que dores existem ou podem estar existindo aí para começar um novo negócio, enxergar oportunidade. E daí a minha ideia hoje aqui na conversa contigo, dado que eu já te apresentei mais ou menos como é que funciona a aplicação, é se do teu ponto de vista isso faz sentido, isso geraria valor para você, eu acho que você é um usuário ideal para essa minha aplicação, e daí eu queria entender mais um pouquinho da tua opinião. Eu acho que faz sentido, mas aí eu tenho uma dúvida, o Reddit não são só dúvidas técnicas ou dúvidas gerais? São dúvidas gerais, na verdade qualquer coisa. E aí do que eu puxo do Reddit, são geralmente perguntas ali no nicho de, perguntas num assunto de empreendedorismo. Eu puxo comentários relacionados a empreendedorismo, relacionados a perguntas em geral, relacionados a terapia, economia, e enfim, para eu ter tipo, não só comentários voltados ao mundo do empreendedorismo, mas também ter uma ideia geral assim, em outras áreas. Eu acho que você resolve a dor do empreendedor de às vezes não achar uma dor, então isso ajuda ele nisso, mas o que eu acho que você podia fazer para complementar é transformar isso talvez num chatbot, em que o cara conseguisse fazer perguntas sobre as dores. Ah, o que específico aqui é, que dor que o cara teve aqui na área de economia? E aí ele ir lá e falar coisas específicas, e às vezes tirar as próprias dúvidas, tipo, como é que foi resolvida essa dor? Entendeu? Uma linha mais assim, mas eu acho a ideia boa e eu acho que o projeto vai funcionar. Então fechou, é isso? Agradeço a participação. Boa.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "audio_file= open(\"../data/audio/Insper-Instituto-de-Ensino-e-Pesquisa-10.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a248ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom, boa noite. Eu tô aqui com o João e... Bom, João, hoje basicamente eu quero apresentar um pouco do nosso projeto da matéria da eletiva de INLP, em que basicamente é uma aplicação voltada mais para empreendedores, né? Os nossos usuários são empreendedores e às vezes empreendedores que estão mais ali no processo de discovery, que querem encontrar oportunidades ali de montar o próprio negócio, que querem dedicar dores. E a ideia da aplicação é justamente ajudar nesse processo. E para começar, eu queria começar te perguntando se você conhece o Reddit, a plataforma, a rede social. Conheço. Bom, acho que você consegue concordar comigo que ela tem... É uma fonte de dados gigantesca, que é uma rede social, né? Sempre ativa e a gente consegue pegar muitos dados interessantes lá, dependendo do qual... Do intuito com o qual a gente quer utilizar esses dados. E a ideia é o quê? É extrair, primeiramente extrair comentários ou postagens do Reddit, né? Em determinados fóruns que a gente pode pré-estabelecer. E, nesse caso, os fóruns a gente está pré-definido um pouco mais ali na área de empreendedorismo, né? Fóruns de empreendedorismo, de economia, saúde, comentários gerais também. E dado que a gente extrai esses comentários, a gente vai passar por uma filtragem com inteligência artificial, né? Que ela vai basicamente classificar se dado uma mensagem, um comentário ou um post, esse comentário revela algum problema que o usuário está sentindo. Ou seja, se o usuário comenta alguma dor, algum problema que ele está passando. E, uma vez que a gente filtra, né? E a gente toma apenas essas mensagens em que revela alguma dor do usuário, a gente agrupa eles em clusters de dores similares, né? Com algoritmo de clusterização. E, uma vez que a gente agrupa, a gente pega para cada cluster, né? Para cada agrupamento. A gente vai utilizar um modelo de linguagem natural para extrair principais tópicos de... Principais dores que existem em cada um desses clusters e retornar um relatório para o empreendedor. E daí... Extração de tópicos? Extração de tópicos. E daí, a ideia aqui é basicamente entender um pouco de como seria a tua perspectiva sobre essa aplicação. Se para tu, como empreendedor, faz sentido, se gera valor para ti. Possíveis comentários que você teria a fazer. Sim, geraria muito valor no sentido de que, hoje em dia, a gente já faz esse tipo de busca, só que manualmente. Quando vai fazer uma coleta de informações sobre uma determinada hipótese que a gente tem, a gente vai coletar informações na internet. E o Reddit é uma fonte em que a gente consegue ver discussões. Obviamente, a gente vai encontrar muito lixo, mas também a gente vai encontrar muita coisa útil que a gente pode tirar das discussões que estão sendo feitas. Então, eu acho que tanto fazer essa clusterização e trazer um resumo com links que você pode acessar o conteúdo, eu acho que pode ser muito interessante. Uma coisa que, além disso, também poderia ser feita, é dentro dos comentários no Reddit, é extrair os links que estão sendo colocados nos comentários. Para a partir desses links, você também extrair informação. Eu acho que poderia ser uma cascata interessante de coleta de informação geral. Legal. E atualmente, a ideia poderia ser, isso seria um relatório semanal, talvez, ou teria algum outro tipo de priorização aí. E, no momento, ela tem uma latência um pouco alta, mas em relação a tempo, se for semanal, uma coisa que vai ser, de certa forma, automatizada ainda, você acha que teria algum problema e tal? Porque leva um tempo para ele pegar, classificar... Mas a maneira que você está fazendo é mandar periódico ou você quer que mande na hora para o cliente quando ele clica um botão, por exemplo? Acho que é mais fácil mandar periódico, porque se fosse mandar na memória... Ou diária, ou semanal, a cada dois dias, não sei. Mas você coloca uma latência que seja suficiente para que dê para coletar informação suficiente para mandar. Show de bola. Então, acho que não teria problema em ter um dia, dois, às vezes, sem informação e depois chegar um resumo. Legal. Então, acho que é isso. Mais alguma coisa? É isso aí. Agradeço.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "audio_file= open(\"../data/audio/Casa-Bauducco-Insper.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c4e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
